---
title: "Multiple Regression"
# subtitle: '(Estimating Linear Relationships)'
author: "Understanding Political Numbers"
date: "March 11, 2019"
output:
  xaringan::moon_reader:
    lib_dir: libs
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    # mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG"
    css: xaringan-themer.css
    nature:
      ratio: "16:9"
      highlightStyle: default
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "https://platform.twitter.com/widgets.js"
seal: false
---

class: inverse, middle, center

# Review


```{r setup-rmd, eval = TRUE, echo = FALSE, warning = FALSE, message = FALSE}

# rmarkdown::render(here::here("lectures", "14-multiple-regression", "14-multiple-regression.Rmd"))
# knitr::purl(here::here("lectures", "14-multiple-regression", "14-multiple-regression.Rmd"), output = here::here("R", "lecture_multiple-regression.R"))

source(here::here("R", "setup-lectures.R"))

# They're good DAGs, Brent
library("dagitty")
library("ggdag")

library("broom")

library("patchwork")

# box
# library("boxr"); box_auth()

# library("viridis")
# library(png)
# library(grid)
# library(gridExtra)

# options(scipen = 99999)


hook_source <- knitr::knit_hooks$get('source')
knitr::knit_hooks$set(source = function(x, options) {
  x <- stringr::str_replace(x, "^[[:blank:]]?([^*].+?)[[:blank:]]*#<<[[:blank:]]*$", "*\\1")
  hook_source(x, options)
})

# chunks:
# hide code and messages
# cache everything
knitr::opts_chunk$set(eval = TRUE, echo = FALSE, 
                      warning = FALSE, message = FALSE,
                      cache = TRUE, 
                      cache.path = here::here("lectures", "cache", "14_"),
                      fig.align = "center", # eval.after = 'fig.cap',
                      fig.retina = 3 # , dpi = 100
                      )

img <- "lectures/14-multiple-regression/img"
```


---

## Review

.left-code[
```{r normal-p, out.width = "100%"}
include_graphics(here(img, "Normal.png"))
```
]

.right-plot[

#### A result is *statistically significant* if is was unlikely to have occurred by chance

**We want to make inferences about the "true" parameters, but we only observe a sample of data.**

***Assuming that the null hypothesis is true,* what would be the *probability* of observing our slope**

**An estimate is *significant* if the probability of getting it, under the null, is "sufficiently low"**

**Null relationships can still "pop" as significant, and "non-null" relationships may fail to show insignificance**
]





---


.pull-left[
## What is a confidence interval?

All estimates are uncertain

95% intervals contain "true parameter" 95% of the time

$\hat{y} = \alpha + \beta x$

Interval is $\mathrm{Estimate} \pm \mathrm{MOE}$

$b \pm \left(1.96 \times se(b)\right)$

Software calculates CIs for you 

]

.pull-right[
```{r, fig.width = 4, fig.height = 5, out.width = "100%"}
ed_mod <- lm(percprof ~ percollege, data = midwest)

tidy_mod <- broom::tidy(ed_mod, conf.int = TRUE) %>%
  mutate(term = case_when(term == "(Intercept)" ~ "Intercept",
                          term == "percollege" ~ "Pct. College"))

scat <- ggplot(midwest, aes(x = percollege, y = percprof)) +
  geom_point(color = "gray", shape = 1) +
  geom_smooth(method = "lm", size = 0.5, color = "black", fill = "steelblue") +
  labs(x = "Percent w/ College Degree",
       y = "Percent w/ \nProfessional Degree",
       caption = "Shaded area is 95% confidence interval") +
  theme_bw()

coefs <- ggplot(tidy_mod, aes(x = term, y = estimate)) +
  geom_hline(yintercept = 0, color = "maroon", linetype = 2) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
  coord_flip() +
  labs(x = NULL, y = "Coefficient Estimate",
       caption = "Bars show 95% confidence intervals",
       title = "Coefficient Plot") +
  theme_bw()

scat / coefs
```
]



---

## Inference issues with $p$ values

--

Null hypothesis testing: Higher quality learning by rejecting inconsistent ideas (*falsifying* the null? Probabilistically?)

--

If we want to be 95% confident, 5% of the "null models" will appear significant

--

Insignificance does *not* mean "no relationship," only that there wasn't enough data to reject the null hypothesis

--

It takes *lots* of data to estimate small effects w/ statistical significance

--

Relationships are everywhere, we just need enough data to make confident inferences about what they are




---

class: middle, inverse, center

# Multiple Regression



---

# "Controlling for" other factors

--

$y$ affected by many potential $w, x, z$ variables

--

**Partial effect:** what would happen to $y$ if I *only* changed $w$

Or, the effect of $w$, "controlling for" $x$ and $z$

--

SES and voting: Income or education?

--

Experiments! 





---

## Multiple regression

.pull-left[
"Simple" or "bivariate" regression (two variables)

\begin{align}
  y = \alpha + \beta x + \epsilon
\end{align}

<br>

"Multiple regression" (many independent variables)

\begin{align}
  y = \alpha + \beta_{1} x_{1} + \beta_{2} x_{2} + \beta_{3} x_{3} + \ldots + \epsilon
\end{align}

]

--

.pull-right[
Predicted value $\hat{y}$ a function of multiple $x$ variables

$\beta_{1}$: the effect of $x_{1}$, *all else constant*

$\beta_{2}$: the effect of $x_{2}$, *all else constant*

$\alpha$: value of $\hat{y}$ when *all* $x$ variables are $0$

$\epsilon$: still leftover error
]



---

## Interpreting Multiple Regression

.pull-left[
```{r cars, echo = TRUE}
library("tidyverse")

# show the car data, convert to 'tibble'
mtcars %>% 
  as_tibble(rownames = "model") %>%
  select(model, mpg, wt, disp)
```

]

--

.pull-right[

\begin{align}
  \text{Miles per gallon} &= \alpha + \beta_{1} \mathrm{weight} + \beta_{2} \mathrm{displacement} + \epsilon
\end{align}

```{r, out.width = "80%"}
include_graphics(here(img, "reg3d.png"))
```
]








---

## Multiple Regression in R

```{r, echo = TRUE}
library("broom") # for tidy() function

# add independent variables with `+`
car_model <- lm(mpg ~ wt + disp, 
                data = mtcars)

tidy(car_model, conf.int = TRUE)
```


---

### Predictions from Multiple Regression


.pull-left[
Conventionally: plot partial effect of one variable, holding everything else at their mean

```{r, echo = TRUE}
# new data frame; disp held at mean
vary_wt <- mtcars %>%
  select(mpg, wt, disp) %>%
  mutate(disp = mean(disp)) 

# predictions using augment()
wt_predictions <- 
  augment(car_model, newdata = vary_wt) %>%
  mutate(MOE = 1.96 * .se.fit,
         lower_bound = .fitted - MOE,
         upper_bound = .fitted + MOE) %>%
  print()
```
]


.pull-right[
```{r, out.width = "100%", fig.width = 6, fig.height = 4}
ggplot(wt_predictions, aes(x = wt, y = .fitted)) +
  geom_ribbon(aes(ymin = lower_bound, ymax = upper_bound),
              fill = "skyblue") +
  geom_line() +
  labs(x = "Weight",
       y = "Predicted MPG",
       caption = "Displacement held constant at its mean value")
```
]



---

```{r, eval = FALSE}

vary_college <- poverty_model %>%
  augment() %>%
  select(-starts_with(".")) %>%
  mutate(popdensity = mean(popdensity)) %>%
  augment(poverty_model, newdata = .) %>%
  print()

vary_popdensity <- poverty_model %>%
  augment() %>%
  select(-starts_with(".")) %>%
  mutate(percollege = mean(percollege)) %>%
  augment(poverty_model, newdata = .) %>%
  print()
```



---

## (Spooky voice) Omitted Variable Bias

```{r spurious, fig.width = 5, fig.height = 3, out.width = "80%", cache= FALSE}
set.seed(12)

coords <- tibble(x = c( 1, 2, 3),
                 y = c(1, 2, 1),
                 name = c("x", "u", "y"))

dagify(x ~ u,
       y ~ u + x,
       exposure = c("u"),
       outcome = c("x", "y"),
       labels = c("u" = "(Omitted)"),
       coords = coords) %>%
  tidy_dagitty(layout = "linear") %>%
  node_parents("y") %>%
  ggplot(aes(x = x, y = y,
             xend = xend, yend = yend)) +
    geom_dag_edges() +
    geom_dag_point(shape = 1, color = "black") +
    geom_dag_text(color = "black") +
    geom_dag_text_repel(aes(label = label), segment.color = "black") +
    scale_color_manual(values = c(primary, secondary)) +
    scale_x_continuous(expand = expand_scale(add = 0.5)) +
    scale_y_continuous(expand = expand_scale(add = 0.5)) +
    theme_dag_blank() + 
    NULL
```






---

class: middle

.pull-left[
## Causality Advice

Correlation â‰  causation



Bad controls


Better causality: control "upstream" variables

- Back-door paths
- Post-treatment bias


For advanced advice: [[1]](https://www.youtube.com/watch?v=l_7yIUqWBmE) and [[2]](https://www.youtube.com/watch?v=0Jc6Kgw5qc0)

]


.pull-right[
```{r, out.width = "60%"}
include_graphics(here(img, "causality.jpg"))
```
]